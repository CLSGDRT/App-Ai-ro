version: '3.8'

services:
  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "5001:5001"
      - "11434:11434" # Port Ollama
    environment:
      - FLASK_APP=api.app
      - FLASK_ENV=prod
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL_PROD=sqlite:////app/database/appairo.db
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_PORT=11434
    volumes:
      - ./app-ai-ro-backend:/app
      - backend-ollama-models:/root/.ollama
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  rq-worker:
    build:
      context: .
      dockerfile: Dockerfile.backend
    environment:
      - REDIS_URL=redis://redis:6379/0
      - FLASK_APP=api.app
      - OLLAMA_BASE_URL=http://backend:11434
    command: >
      /bin/sh -c "sleep 30 && cd /app && python rq_worker.py"
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    volumes:
      - ./app-ai-ro-backend:/app
      - backend-ollama-models:/root/.ollama
    restart: unless-stopped

  image-service:
    build:
      context: .
      dockerfile: Dockerfile.image
    ports:
      - "5004:5004"
    environment:
      - FLASK_APP=app
    volumes:
      - diffusers-models:/root/.cache/huggingface
    depends_on:
      - redis
    restart: unless-stopped

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "5173:80"
    depends_on:
      - backend
    restart: unless-stopped

volumes:
  redis-data:
  backend-ollama-models:
  diffusers-models: